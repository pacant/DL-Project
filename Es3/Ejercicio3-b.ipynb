{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3 b. Traducción Automática de Texto\n",
    "\n",
    "Este ejercicio tiene como objetivo entrenar un modelo para traducción automática de texto (neural machine translation) del inglés a español. Para ello, haremos uso de redes recurrentes y word embeddings. \n",
    "\n",
    "![neural machine translation](img/nmt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Enunciado\n",
    "\n",
    "La traducción de texto se suele realizar con modelos de tipo sequence-to-sequence, donde existe un *encoder* que codifica el lenguaje de entrada, y un *decoder* que genera el texto en el lenguaje de salida. Actualmente esto se realiza empleando redes con auto-atención (transformers), pero para este ejercicio vamos a implementar una red recurrente clásica. \n",
    "\n",
    "La implementación del modelo recurrente la puedes realizar basándote en los ejemplos:\n",
    "1. [Modelo sequence-to-sequence a nivel de caracteres con LSTM](https://keras.io/examples/nlp/lstm_seq2seq/): Este ejemplo de Keras muestra cómo entrenar un modelo seq-to-seq implementado con LSTMs para la traducción de inglés a francés. Está basado en esta antigua entrada del [blog de Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html), donde también se dan las pistas para trabajar a nivel de palabras.\n",
    "2. [Traducción de inglés a español con un transformer](https://keras.io/examples/nlp/neural_machine_translation_with_transformer/): Este ejemplo de Keras muestra como implementar un modelo seq-to-seq de tipo transformer en Keras, y cómo procesar el dataset de traducción de inglés al español con la capa `TextVectorization`.\n",
    "3. [Traducción automática neuronal usando un modelo seq2seq a nivel de palabra](https://medium.com/@dev.elect.iitd/neural-machine-translation-using-word-level-seq2seq-model-47538cba8cd7): Este proyecto, cuyo código está disponible en este [repositorio de github](https://github.com/devm2024/nmt_keras), trabaja con un modelo seq-to-seq usando como tokens las palabras de las frases, para la traducción del inglés al francés. Incluye una capa de embedding vacía.\n",
    "\n",
    "Tu trabajo consistirá en adaptar el código de los ejemplos anteriores para entrenar un modelo seq-to-seq basado en LSTMs para la traducción del inglés a español. Puedes tokenizar el texto con `Tokenizer` así como con `TextVectorization`, según te convenga mejor para construir las entradas. Sin embargo, debes utilizar una capa de word embedding pre-entrenada para inglés (Glove, Word2Vec...), como vimos en las prácticas. Es suficiente con entrenar tan solo un modelo de estas características.\n",
    "\n",
    "*De forma opcional*, se valorará la comparativa del modelo obtenido con un modelo pre-entrenado de HuggingFace para la traducción de inglés al español con el dataset descargado. También se dará un punto extra se si usan métricas BLEU y ROUGE para comparar el rendimiento de los modelos.\n",
    "\n",
    "**IMPORTANTE**: Se permiten cambios en el código para adaptarlo a la GPU empleada. Es posible que el modelo no se pueda cargar al completo en la GPU, por lo que se puede simplificar (usar un subconjunto más pequeño, un tamaño de batch más pequeño, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrega\n",
    "\n",
    "La entrega de este ejercicio se realiza a través de la tarea creada para tal efecto en Enseñanza Virtual. Tienes que entregar un notebook, y el HTML generado a partir de él, cuyas celdas estén ya evaluadas.\n",
    "\n",
    "La estructura del notebook debe contener los siguientes apartados:\n",
    "\n",
    "0. Cabecera: nombre y apellidos.\n",
    "1. Dataset: descripción, carga y procesado.\n",
    "2. Selección y carga del word embedding para el inglés.\n",
    "3. Modelo y configuración creadas en Keras y su entrenamiento. Debe incluir una explicación razonada de los componentes, y de la selección de valores como el número de unidades en las redes recurrentes (LSTM/GRU), dimensión del embedding, etc.\n",
    "5. Análisis de resultados con comparativa respecto del trabajo original ([ejemplo 2](https://keras.io/examples/nlp/neural_machine_translation_with_transformer/)) basado en transformers (*no es necesario mejorarlo*). Si se hace la parte opcional (comparar con un modelo pre-entrenado de HuggingFace), indicar la comparativa. El análisis puede ser cualitativo, haciendo pruebas de texto. *Se evaluará con 1 punto extra si se hace un análisis con métricas como BLEU y ROUGE (se pueden usar desde KerasNLP).*\n",
    "6. Bibliografía utilizada (enlaces web, material de clase, libros, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Nota importante\n",
    "-----\n",
    "**HONESTIDAD ACADÉMICA Y COPIAS: un trabajo práctico es un examen, por lo que\n",
    "debe realizarse de manera individual. La discusión y el intercambio de\n",
    "información de carácter general con los compañeros se permite (e incluso se\n",
    "recomienda), pero NO AL NIVEL DE CÓDIGO. Igualmente el remitir código de\n",
    "terceros, OBTENIDO A TRAVÉS DE LA RED o cualquier otro medio, se considerará\n",
    "plagio.** \n",
    "\n",
    "**Cualquier plagio o compartición de código que se detecte significará\n",
    "automáticamente la calificación de CERO EN LA ASIGNATURA para TODOS los\n",
    "alumnos involucrados. Por tanto a estos alumnos NO se les conservará, para\n",
    "futuras convocatorias, ninguna nota que hubiesen obtenido hasta el momento.\n",
    "SIN PERJUICIO DE OTRAS MEDIDAS DE CARÁCTER DISCIPLINARIO QUE SE PUDIERAN\n",
    "TOMAR.**\n",
    "\n",
    "-----\n",
    "\n",
    "## 3. Código para iniciarse\n",
    "\n",
    "En el [ejemplo 2](https://keras.io/examples/nlp/neural_machine_translation_with_transformer/) indicado anteriormente, se puede ver cómo descargar y procesar un dataset de traducción del inglés al español. Abajo se deja igualmente la celda para descargar y cargar el dataset (se puede evaluar las veces que haga falta, ya que se descarga tan solo una vez, y se almacena en el directorio $HOME/.keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization, Embedding, LSTM, Dense, Input\n",
    "from tensorflow import keras\n",
    "\n",
    "text_file = keras.utils.get_file(\n",
    "    fname=\"spa-eng.zip\",\n",
    "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset viene en el siguiente formato: cada línea del fichero es una frase en inglés seguida por la correspondiente en español, separados por un tabulador. La siguiente celda separa cada frase en cada idioma, y además al español (idioma destino) le añade los tokens [start] y [end], necesarios para controlar la generación de la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    eng, spa = line.split(\"\\t\")\n",
    "    spa = \"[start] \" + spa + \" [end]\"\n",
    "    text_pairs.append((eng, spa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('She always cries when she chops onions.', '[start] Siempre llora cuando pica cebolla. [end]')\n",
      "(\"We're joking.\", '[start] Estamos bromeando. [end]')\n",
      "('I made fun of him.', '[start] Me burlé de él. [end]')\n",
      "('When I was a child, I was spanked if I did something wrong.', '[start] Cuando era pequeño, me daban unos azotes cuando hacía algo malo. [end]')\n",
      "('Come anytime.', '[start] Ven cuando quieras. [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for _ in range(5):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118964"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118964 total pairs\n",
      "83276 training pairs\n",
      "17844 validation pairs\n",
      "17844 test pairs\n"
     ]
    }
   ],
   "source": [
    "# Este código separa el conjunto de entrenamiento en train, val y test\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
    "    \n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelos tipo seq-to-seq con Teacher Forcing\n",
    "\n",
    "Un modelo de tipo sequence-to-sequence (seq-to-seq, o simplemente, seq2seq), se caracterizan porque reciben como entrada secuencias (texto) y generan como salida otra secuencia (texto). En nuestro caso la entrada será una frase en inglés y la salida será la frase en español.\n",
    "\n",
    "Estos modelos se caracterizan porque están divididos en dos partes: un *encoder* y un *decoder*. Estos dos modelos se componen de la siguiente forma para conformar el modelo seq2seq (también conocido como *teacher forcing*):\n",
    "\n",
    "![neural machine translation](img/seq2seq-teacher-forcing.png)\n",
    "\n",
    "\n",
    "* El **encoder**:\n",
    "  * **Recibe** la *secuencia de entrada* (frase en inglés). Cada token será una palabra, y se usará su representación con un word embedding pre-entrenado (Glove, Word2vec, FastText ...).\n",
    "  * **Devuelve** el *estado oculto* de la última neurona de la red recurrente, que sirve como continuación para el decoder. Si es una LSTM, será el último hidden state y el cell state.\n",
    "* El **decoder**:\n",
    "  * **Recibe**:\n",
    "    * El *último estado oculto (hidden state, cell state)* generado en el encoder.\n",
    "    * La *secuencia de salida*, incluyendo el [start]. \n",
    "  * **Devuelve** la secuencia de salida desplazada en 1 posición. Si la frase original es \"[start] Hablé con Tom [end]\", la salida será \"Hablé con Tom [end]\".\n",
    "  \n",
    "La configuración del decoder es así porque se empleará en tiempo de inferencia de forma *auto-regresiva*; es decir: empezamos con tan solo \"[start]\", y el decoder generará la siguiente palabra (por ejemplo, \"hablé\"); esta palabra se concatena a la solución parcial, teniendo \"[start] hablé\"; se repite el proceso, le damos al decoder esa solución parcial y dará la siguiente palabra (por ejemplo, \"con\"), y la añadimos a la solución parcial \"[start] hablé con\", y así hasta alcanzar el token [end]. \n",
    "  \n",
    "Recuerda que la salida del modelo indicará en formato one-hot cual es la siguiente palabra. Las entradas (del encoder y del decoder) serán las secuencias de los tokens en formato one-hot (que después pasarán por la correspondiente capa de embedding, siendo para el inglés un embedding pre-entrenado).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with vectorization. I use TextVectorization here, using the standard standardization for english words, and a custom one for spanish words (adding ¿ and without removing brackets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "import string\n",
    "import re \n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "batch_size = 64\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf_strings.lower(input_string)\n",
    "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "\n",
    "eng_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "spa_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_eng_texts = [pair[0] for pair in train_pairs]\n",
    "train_spa_texts = [pair[1] for pair in train_pairs]\n",
    "\n",
    "for i in range(len(train_pairs)):\n",
    "    train_eng_texts[i] = train_eng_texts[i].lower()\n",
    "    train_spa_texts[i] = train_spa_texts[i].lower()\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "test_spa_texts = [pair[1] for pair in test_pairs]\n",
    "\n",
    "val_eng_texts = [pair[0] for pair in val_pairs]\n",
    "val_spa_texts = [pair[1] for pair in val_pairs]\n",
    "\n",
    "for i in range(len(test_eng_texts)):\n",
    "    test_eng_texts[i] = test_eng_texts[i].lower()\n",
    "    test_spa_texts[i] = test_spa_texts[i].lower()\n",
    "    val_eng_texts[i] = val_eng_texts[i].lower()\n",
    "    val_spa_texts[i] = val_spa_texts[i].lower()\n",
    "\n",
    "eng_vectorization.adapt(train_eng_texts)\n",
    "spa_vectorization.adapt(train_spa_texts)\n",
    "\n",
    "eng_vocab = eng_vectorization.get_vocabulary()\n",
    "spa_vocab = spa_vectorization.get_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we format the dataset. First we apply vectorization and then the dataset is formatted with encoder inputs (english sentences), decoder inputs (spanish sentences without the end), and the labels (spanish sentences displaced by one).\n",
    "\n",
    "I tried to vectorize/tokenize and then encode with one-hot encoding, but since the vocabulary is big and we have a lot of sentences, every time that i tried i had a dead kernel error. It works if i reduce the sentences but then the accuracy is awful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "\n",
    "def format_dataset(data_eng, data_spa):\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": data_eng,\n",
    "            \"decoder_inputs\": data_spa[:, :-1],\n",
    "        },\n",
    "        data_spa[:, 1:]\n",
    "    )\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    \n",
    "    data_eng = eng_vectorization(np.array(eng_texts))\n",
    "\n",
    "    data_spa= spa_vectorization(np.array(spa_texts))\n",
    "    formatted_data = format_dataset(data_eng, data_spa)\n",
    "    \n",
    "    return formatted_data\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)\n",
    "test_ds = make_dataset(test_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing and creating an embedding matrix for Glove based on english sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "glove_dir = 'glove.6B'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((len(eng_vocab), embedding_dim))\n",
    "l= 0\n",
    "for i,word in enumerate(eng_vocab):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the model. First the pre trained embedding layer, then a LSTM layer for the encoder. Same thing for the decoder but the embedding layer is not pre trained and the LSTM layer take as initial state, the final state of the encoder LSTM. The last layer is a softmax for classification.\n",
    "\n",
    "In the embedding layer, since we have padded sequences, mask_zero=True is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras import optimizers\n",
    "\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "\n",
    "en_x= Embedding(input_dim=len(eng_vocab), output_dim=embedding_dim, mask_zero=True,weights=[embedding_matrix], trainable=False)(encoder_inputs)\n",
    "\n",
    "encoder = LSTM(embedding_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(en_x)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "dex=  Embedding(input_dim=len(spa_vocab),mask_zero=True, output_dim=embedding_dim)\n",
    "final_dex= dex(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(embedding_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(units=len(spa_vocab), activation='softmax')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, None, 100)    1202900     ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, None, 100)    1500000     ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  [(None, 100),        80400       ['embedding_5[0][0]']            \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  [(None, None, 100),  80400       ['embedding_6[0][0]',            \n",
      "                                 (None, 100),                     'lstm_6[0][1]',                 \n",
      "                                 (None, 100)]                     'lstm_6[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, None, 15000)  1515000     ['lstm_7[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,378,700\n",
      "Trainable params: 3,175,800\n",
      "Non-trainable params: 1,202,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1302/1302 [==============================] - 199s 151ms/step - loss: 6.1964 - acc: 0.1230 - val_loss: 5.2902 - val_acc: 0.1422\n",
      "Epoch 2/100\n",
      "1302/1302 [==============================] - 208s 160ms/step - loss: 5.1062 - acc: 0.2635 - val_loss: 4.8337 - val_acc: 0.2902\n",
      "Epoch 3/100\n",
      "1302/1302 [==============================] - 214s 164ms/step - loss: 4.8085 - acc: 0.2981 - val_loss: 4.6377 - val_acc: 0.3083\n",
      "Epoch 4/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 4.6368 - acc: 0.3147 - val_loss: 4.4866 - val_acc: 0.3243\n",
      "Epoch 5/100\n",
      "1302/1302 [==============================] - 213s 164ms/step - loss: 4.4832 - acc: 0.3298 - val_loss: 4.3476 - val_acc: 0.3386\n",
      "Epoch 6/100\n",
      "1302/1302 [==============================] - 209s 160ms/step - loss: 4.3511 - acc: 0.3444 - val_loss: 4.2332 - val_acc: 0.3539\n",
      "Epoch 7/100\n",
      "1302/1302 [==============================] - 214s 164ms/step - loss: 4.2378 - acc: 0.3579 - val_loss: 4.1281 - val_acc: 0.3659\n",
      "Epoch 8/100\n",
      "1302/1302 [==============================] - 212s 163ms/step - loss: 4.1340 - acc: 0.3694 - val_loss: 4.0335 - val_acc: 0.3771\n",
      "Epoch 9/100\n",
      "1302/1302 [==============================] - 208s 160ms/step - loss: 4.0419 - acc: 0.3803 - val_loss: 3.9527 - val_acc: 0.3865\n",
      "Epoch 10/100\n",
      "1302/1302 [==============================] - 207s 159ms/step - loss: 3.9608 - acc: 0.3898 - val_loss: 3.8763 - val_acc: 0.3956\n",
      "Epoch 11/100\n",
      "1302/1302 [==============================] - 209s 161ms/step - loss: 3.8869 - acc: 0.3980 - val_loss: 3.8101 - val_acc: 0.4021\n",
      "Epoch 12/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 3.8213 - acc: 0.4061 - val_loss: 3.7598 - val_acc: 0.4078\n",
      "Epoch 13/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 3.7626 - acc: 0.4135 - val_loss: 3.6990 - val_acc: 0.4173\n",
      "Epoch 14/100\n",
      "1302/1302 [==============================] - 212s 163ms/step - loss: 3.7072 - acc: 0.4208 - val_loss: 3.6494 - val_acc: 0.4247\n",
      "Epoch 15/100\n",
      "1302/1302 [==============================] - 212s 163ms/step - loss: 3.6559 - acc: 0.4277 - val_loss: 3.6062 - val_acc: 0.4281\n",
      "Epoch 16/100\n",
      "1302/1302 [==============================] - 215s 165ms/step - loss: 3.6103 - acc: 0.4342 - val_loss: 3.5682 - val_acc: 0.4336\n",
      "Epoch 17/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 3.5692 - acc: 0.4401 - val_loss: 3.5282 - val_acc: 0.4408\n",
      "Epoch 18/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 3.5308 - acc: 0.4459 - val_loss: 3.4974 - val_acc: 0.4453\n",
      "Epoch 19/100\n",
      "1302/1302 [==============================] - 210s 161ms/step - loss: 3.4931 - acc: 0.4512 - val_loss: 3.4605 - val_acc: 0.4516\n",
      "Epoch 20/100\n",
      "1302/1302 [==============================] - 214s 164ms/step - loss: 3.4548 - acc: 0.4563 - val_loss: 3.4224 - val_acc: 0.4554\n",
      "Epoch 21/100\n",
      "1302/1302 [==============================] - 216s 166ms/step - loss: 3.4180 - acc: 0.4610 - val_loss: 3.3888 - val_acc: 0.4591\n",
      "Epoch 22/100\n",
      "1302/1302 [==============================] - 216s 166ms/step - loss: 3.3837 - acc: 0.4657 - val_loss: 3.3598 - val_acc: 0.4630\n",
      "Epoch 23/100\n",
      "1302/1302 [==============================] - 212s 162ms/step - loss: 3.3517 - acc: 0.4699 - val_loss: 3.3313 - val_acc: 0.4676\n",
      "Epoch 24/100\n",
      "1302/1302 [==============================] - 350s 269ms/step - loss: 3.3225 - acc: 0.4741 - val_loss: 3.3095 - val_acc: 0.4720\n",
      "Epoch 25/100\n",
      "1302/1302 [==============================] - 219s 168ms/step - loss: 3.2956 - acc: 0.4780 - val_loss: 3.2858 - val_acc: 0.4750\n",
      "Epoch 26/100\n",
      "1302/1302 [==============================] - 218s 168ms/step - loss: 3.2702 - acc: 0.4816 - val_loss: 3.2650 - val_acc: 0.4771\n",
      "Epoch 27/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 3.2456 - acc: 0.4853 - val_loss: 3.2443 - val_acc: 0.4799\n",
      "Epoch 28/100\n",
      "1302/1302 [==============================] - 210s 162ms/step - loss: 3.2228 - acc: 0.4888 - val_loss: 3.2229 - val_acc: 0.4836\n",
      "Epoch 29/100\n",
      "1302/1302 [==============================] - 209s 161ms/step - loss: 3.2004 - acc: 0.4925 - val_loss: 3.2027 - val_acc: 0.4871\n",
      "Epoch 30/100\n",
      "1302/1302 [==============================] - 209s 160ms/step - loss: 3.1788 - acc: 0.4959 - val_loss: 3.1873 - val_acc: 0.4888\n",
      "Epoch 31/100\n",
      "1302/1302 [==============================] - 212s 163ms/step - loss: 3.1578 - acc: 0.4993 - val_loss: 3.1675 - val_acc: 0.4912\n",
      "Epoch 32/100\n",
      "1302/1302 [==============================] - 212s 163ms/step - loss: 3.1388 - acc: 0.5023 - val_loss: 3.1530 - val_acc: 0.4947\n",
      "Epoch 33/100\n",
      "1302/1302 [==============================] - 210s 162ms/step - loss: 3.1206 - acc: 0.5052 - val_loss: 3.1389 - val_acc: 0.4977\n",
      "Epoch 34/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 3.1022 - acc: 0.5082 - val_loss: 3.1225 - val_acc: 0.4986\n",
      "Epoch 35/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 3.0853 - acc: 0.5110 - val_loss: 3.1098 - val_acc: 0.5004\n",
      "Epoch 36/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 3.0675 - acc: 0.5135 - val_loss: 3.0929 - val_acc: 0.5035\n",
      "Epoch 37/100\n",
      "1302/1302 [==============================] - 207s 159ms/step - loss: 3.0507 - acc: 0.5164 - val_loss: 3.0793 - val_acc: 0.5059\n",
      "Epoch 38/100\n",
      "1302/1302 [==============================] - 215s 165ms/step - loss: 3.0353 - acc: 0.5186 - val_loss: 3.0692 - val_acc: 0.5082\n",
      "Epoch 39/100\n",
      "1302/1302 [==============================] - 215s 165ms/step - loss: 3.0216 - acc: 0.5212 - val_loss: 3.0533 - val_acc: 0.5106\n",
      "Epoch 40/100\n",
      "1302/1302 [==============================] - 215s 165ms/step - loss: 3.0075 - acc: 0.5237 - val_loss: 3.0439 - val_acc: 0.5120\n",
      "Epoch 41/100\n",
      "1302/1302 [==============================] - 216s 166ms/step - loss: 2.9944 - acc: 0.5259 - val_loss: 3.0339 - val_acc: 0.5140\n",
      "Epoch 42/100\n",
      "1302/1302 [==============================] - 216s 166ms/step - loss: 2.9802 - acc: 0.5282 - val_loss: 3.0213 - val_acc: 0.5159\n",
      "Epoch 43/100\n",
      "1302/1302 [==============================] - 225s 173ms/step - loss: 2.9682 - acc: 0.5304 - val_loss: 3.0133 - val_acc: 0.5168\n",
      "Epoch 44/100\n",
      "1302/1302 [==============================] - 221s 169ms/step - loss: 2.9569 - acc: 0.5323 - val_loss: 3.0024 - val_acc: 0.5198\n",
      "Epoch 45/100\n",
      "1302/1302 [==============================] - 220s 169ms/step - loss: 2.9460 - acc: 0.5343 - val_loss: 2.9926 - val_acc: 0.5219\n",
      "Epoch 46/100\n",
      "1302/1302 [==============================] - 219s 168ms/step - loss: 2.9346 - acc: 0.5364 - val_loss: 2.9858 - val_acc: 0.5233\n",
      "Epoch 47/100\n",
      "1302/1302 [==============================] - 222s 171ms/step - loss: 2.9250 - acc: 0.5383 - val_loss: 2.9781 - val_acc: 0.5245\n",
      "Epoch 48/100\n",
      "1302/1302 [==============================] - 223s 171ms/step - loss: 2.9161 - acc: 0.5399 - val_loss: 2.9734 - val_acc: 0.5260\n",
      "Epoch 49/100\n",
      "1302/1302 [==============================] - 218s 167ms/step - loss: 2.9075 - acc: 0.5418 - val_loss: 2.9630 - val_acc: 0.5267\n",
      "Epoch 50/100\n",
      "1302/1302 [==============================] - 220s 169ms/step - loss: 2.8996 - acc: 0.5437 - val_loss: 2.9584 - val_acc: 0.5280\n",
      "Epoch 51/100\n",
      "1302/1302 [==============================] - 222s 171ms/step - loss: 2.8907 - acc: 0.5451 - val_loss: 2.9514 - val_acc: 0.5307\n",
      "Epoch 52/100\n",
      "1302/1302 [==============================] - 218s 168ms/step - loss: 2.8812 - acc: 0.5467 - val_loss: 2.9430 - val_acc: 0.5310\n",
      "Epoch 53/100\n",
      "1302/1302 [==============================] - 220s 169ms/step - loss: 2.8730 - acc: 0.5485 - val_loss: 2.9372 - val_acc: 0.5321\n",
      "Epoch 54/100\n",
      "1302/1302 [==============================] - 217s 167ms/step - loss: 2.8642 - acc: 0.5502 - val_loss: 2.9316 - val_acc: 0.5335\n",
      "Epoch 55/100\n",
      "1302/1302 [==============================] - 214s 165ms/step - loss: 2.8564 - acc: 0.5517 - val_loss: 2.9271 - val_acc: 0.5334\n",
      "Epoch 56/100\n",
      "1302/1302 [==============================] - 213s 164ms/step - loss: 2.8500 - acc: 0.5534 - val_loss: 2.9208 - val_acc: 0.5357\n",
      "Epoch 57/100\n",
      "1302/1302 [==============================] - 216s 166ms/step - loss: 2.8445 - acc: 0.5549 - val_loss: 2.9173 - val_acc: 0.5360\n",
      "Epoch 58/100\n",
      "1302/1302 [==============================] - 224s 172ms/step - loss: 2.8399 - acc: 0.5563 - val_loss: 2.9162 - val_acc: 0.5373\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302/1302 [==============================] - 223s 171ms/step - loss: 2.8357 - acc: 0.5579 - val_loss: 2.9138 - val_acc: 0.5375\n",
      "Epoch 60/100\n",
      "1302/1302 [==============================] - 224s 172ms/step - loss: 2.8312 - acc: 0.5592 - val_loss: 2.9072 - val_acc: 0.5393\n",
      "Epoch 61/100\n",
      "1302/1302 [==============================] - 222s 171ms/step - loss: 2.8266 - acc: 0.5606 - val_loss: 2.9052 - val_acc: 0.5409\n",
      "Epoch 62/100\n",
      "1302/1302 [==============================] - 223s 171ms/step - loss: 2.8220 - acc: 0.5616 - val_loss: 2.9020 - val_acc: 0.5407\n",
      "Epoch 63/100\n",
      "1302/1302 [==============================] - 221s 169ms/step - loss: 2.8176 - acc: 0.5629 - val_loss: 2.9002 - val_acc: 0.5425\n",
      "Epoch 64/100\n",
      "1302/1302 [==============================] - 222s 170ms/step - loss: 2.8139 - acc: 0.5642 - val_loss: 2.9003 - val_acc: 0.5422\n",
      "Epoch 65/100\n",
      "1302/1302 [==============================] - 222s 170ms/step - loss: 2.8112 - acc: 0.5652 - val_loss: 2.8967 - val_acc: 0.5430\n",
      "Epoch 66/100\n",
      "1302/1302 [==============================] - 222s 171ms/step - loss: 2.8084 - acc: 0.5664 - val_loss: 2.8969 - val_acc: 0.5432\n",
      "Epoch 67/100\n",
      "1302/1302 [==============================] - 222s 170ms/step - loss: 2.8060 - acc: 0.5673 - val_loss: 2.8954 - val_acc: 0.5440\n",
      "Epoch 68/100\n",
      "1302/1302 [==============================] - 221s 170ms/step - loss: 2.8033 - acc: 0.5685 - val_loss: 2.8923 - val_acc: 0.5449\n",
      "Epoch 69/100\n",
      "1302/1302 [==============================] - 221s 169ms/step - loss: 2.8011 - acc: 0.5696 - val_loss: 2.8905 - val_acc: 0.5457\n",
      "Epoch 70/100\n",
      "1302/1302 [==============================] - 220s 169ms/step - loss: 2.7989 - acc: 0.5708 - val_loss: 2.8917 - val_acc: 0.5468\n",
      "Epoch 71/100\n",
      "1302/1302 [==============================] - 225s 173ms/step - loss: 2.7960 - acc: 0.5719 - val_loss: 2.8903 - val_acc: 0.5468\n",
      "Epoch 72/100\n",
      "1302/1302 [==============================] - 228s 175ms/step - loss: 2.7936 - acc: 0.5730 - val_loss: 2.8911 - val_acc: 0.5475\n",
      "Epoch 73/100\n",
      "1302/1302 [==============================] - 228s 175ms/step - loss: 2.7914 - acc: 0.5741 - val_loss: 2.8901 - val_acc: 0.5480\n",
      "Epoch 74/100\n",
      "1302/1302 [==============================] - 219s 168ms/step - loss: 2.7895 - acc: 0.5749 - val_loss: 2.8858 - val_acc: 0.5485\n",
      "Epoch 75/100\n",
      "1302/1302 [==============================] - 217s 167ms/step - loss: 2.7874 - acc: 0.5761 - val_loss: 2.8852 - val_acc: 0.5506\n",
      "Epoch 76/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 2.7851 - acc: 0.5770 - val_loss: 2.8855 - val_acc: 0.5495\n",
      "Epoch 77/100\n",
      "1302/1302 [==============================] - 209s 161ms/step - loss: 2.7825 - acc: 0.5781 - val_loss: 2.8824 - val_acc: 0.5502\n",
      "Epoch 78/100\n",
      "1302/1302 [==============================] - 210s 161ms/step - loss: 2.7796 - acc: 0.5789 - val_loss: 2.8826 - val_acc: 0.5517\n",
      "Epoch 79/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 2.7765 - acc: 0.5799 - val_loss: 2.8815 - val_acc: 0.5525\n",
      "Epoch 80/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 2.7744 - acc: 0.5807 - val_loss: 2.8792 - val_acc: 0.5530\n",
      "Epoch 81/100\n",
      "1302/1302 [==============================] - 210s 161ms/step - loss: 2.7721 - acc: 0.5817 - val_loss: 2.8774 - val_acc: 0.5529\n",
      "Epoch 82/100\n",
      "1302/1302 [==============================] - 207s 159ms/step - loss: 2.7690 - acc: 0.5827 - val_loss: 2.8795 - val_acc: 0.5530\n",
      "Epoch 83/100\n",
      "1302/1302 [==============================] - 206s 158ms/step - loss: 2.7660 - acc: 0.5834 - val_loss: 2.8776 - val_acc: 0.5533\n",
      "Epoch 84/100\n",
      "1302/1302 [==============================] - 205s 158ms/step - loss: 2.7631 - acc: 0.5842 - val_loss: 2.8782 - val_acc: 0.5544\n",
      "Epoch 85/100\n",
      "1302/1302 [==============================] - 211s 162ms/step - loss: 2.7599 - acc: 0.5851 - val_loss: 2.8770 - val_acc: 0.5546\n",
      "Epoch 86/100\n",
      "1302/1302 [==============================] - 210s 161ms/step - loss: 2.7567 - acc: 0.5859 - val_loss: 2.8760 - val_acc: 0.5548\n",
      "Epoch 87/100\n",
      "1302/1302 [==============================] - 208s 160ms/step - loss: 2.7535 - acc: 0.5867 - val_loss: 2.8695 - val_acc: 0.5554\n",
      "Epoch 88/100\n",
      "1302/1302 [==============================] - 213s 164ms/step - loss: 2.7500 - acc: 0.5875 - val_loss: 2.8713 - val_acc: 0.5563\n",
      "Epoch 89/100\n",
      "1302/1302 [==============================] - 212s 163ms/step - loss: 2.7463 - acc: 0.5881 - val_loss: 2.8678 - val_acc: 0.5561\n",
      "Epoch 90/100\n",
      "1302/1302 [==============================] - 210s 161ms/step - loss: 2.7430 - acc: 0.5888 - val_loss: 2.8642 - val_acc: 0.5563\n",
      "Epoch 91/100\n",
      "1302/1302 [==============================] - 1217s 936ms/step - loss: 2.7397 - acc: 0.5895 - val_loss: 2.8657 - val_acc: 0.5570\n",
      "Epoch 92/100\n",
      "1302/1302 [==============================] - 2130s 2s/step - loss: 2.7360 - acc: 0.5905 - val_loss: 2.8633 - val_acc: 0.5584\n",
      "Epoch 93/100\n",
      "1302/1302 [==============================] - 665s 511ms/step - loss: 2.7320 - acc: 0.5912 - val_loss: 2.8608 - val_acc: 0.5588\n",
      "Epoch 94/100\n",
      "1302/1302 [==============================] - 1280s 984ms/step - loss: 2.7284 - acc: 0.5919 - val_loss: 2.8611 - val_acc: 0.5586\n",
      "Epoch 95/100\n",
      "1302/1302 [==============================] - 2229s 2s/step - loss: 2.7243 - acc: 0.5927 - val_loss: 2.8577 - val_acc: 0.5586\n",
      "Epoch 96/100\n",
      "1302/1302 [==============================] - 1191s 915ms/step - loss: 2.7191 - acc: 0.5935 - val_loss: 2.8558 - val_acc: 0.5585\n",
      "Epoch 97/100\n",
      "1302/1302 [==============================] - 2148s 2s/step - loss: 2.7135 - acc: 0.5944 - val_loss: 2.8529 - val_acc: 0.5594\n",
      "Epoch 98/100\n",
      "1302/1302 [==============================] - 1439s 1s/step - loss: 2.7098 - acc: 0.5949 - val_loss: 2.8486 - val_acc: 0.5595\n",
      "Epoch 99/100\n",
      "1302/1302 [==============================] - 1174s 903ms/step - loss: 2.7041 - acc: 0.5956 - val_loss: 2.8445 - val_acc: 0.5598\n",
      "Epoch 100/100\n",
      "1302/1302 [==============================] - 137s 105ms/step - loss: 2.6981 - acc: 0.5965 - val_loss: 2.8414 - val_acc: 0.5604\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [train_ds[0][\"encoder_inputs\"], train_ds[0][\"decoder_inputs\"]],\n",
    "    train_ds[1],\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(\n",
    "        [val_ds[0][\"encoder_inputs\"], val_ds[0][\"decoder_inputs\"]],\n",
    "        val_ds[1]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_lstm_mask.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = {word: index for index, word in enumerate(eng_vocab)}\n",
    "target_token_index = {word: index for index, word in enumerate(spa_vocab)}\n",
    "\n",
    "eng_index_to_word = dict(enumerate(eng_vocab))\n",
    "spa_index_to_word = dict(enumerate(spa_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create the encoder and the decoder for making predictions from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, None, 100)         1202900   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               [(None, 100),             80400     \n",
      "                              (None, 100),                       \n",
      "                              (None, 100)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,283,300\n",
      "Trainable params: 80,400\n",
      "Non-trainable params: 1,202,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()\n",
    "\n",
    "decoder_state_input_h = Input(shape=(embedding_dim,))\n",
    "decoder_state_input_c = Input(shape=(embedding_dim,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "final_dex2= dex(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for decoding the sequence. First it pass the input sequence to the encoder, then it starts generating the target sequence from '[start]' and from states values of encoder's lstm.\n",
    "\n",
    "output_tokens will contain for each word of the sequence, the probability in the entire vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = target_token_index['[start]']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = spa_index_to_word[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "      \n",
    "        if (sampled_char == '[end]' or len(decoded_sentence) > 100):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "-\n",
      "Input sentence: ['tom is old.']\n",
      "Decoded sentence:  tom es viejo [end]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "-\n",
      "Input sentence: ['what kind of movies do you like to watch?']\n",
      "Decoded sentence:  qué tipo de te gusta ver a televisión [end]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "-\n",
      "Input sentence: ['the old castle lay in ruins.']\n",
      "Decoded sentence:  la ciudad se [UNK] en la cama [end]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "-\n",
      "Input sentence: [\"tom doesn't believe in ghosts.\"]\n",
      "Decoded sentence:  tom no cree en la gente [end]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "-\n",
      "Input sentence: ['anything is infinitely better than nothing.']\n",
      "Decoded sentence:  nada es más que un poco más de esto [end]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "-\n",
      "Input sentence: [\"tom couldn't decide when to begin.\"]\n",
      "Decoded sentence:  tom no se puede cuándo [UNK] [end]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "-\n",
      "Input sentence: ['he came home at almost midnight.']\n",
      "Decoded sentence:  [UNK] se fue a casa en casa [end]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "-\n",
      "Input sentence: ['which one do you think is correct?']\n",
      "Decoded sentence:  cuál es lo mejor que tienes [end]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "-\n",
      "Input sentence: ['queen liliuokalani was forced to surrender.']\n",
      "Decoded sentence:  el niño se fue [UNK] para que [UNK] [end]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "-\n",
      "Input sentence: ['it was the calm before the storm.']\n",
      "Decoded sentence:  estaba al lo perro por la fiesta [end]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    seq_index = random.randint(0, len(test_eng_texts))\n",
    "    input_seq = test_ds[0]['encoder_inputs'][seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', test_eng_texts[seq_index: seq_index + 1])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the translation is absolutely not perfect, but in some cases is correct. I would say that maybe using a seq2seq with Transformer can bring to better results. \n",
    "Sometimes there is the [UNK] char because the spanish vocabulary was bigger than the max length set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
